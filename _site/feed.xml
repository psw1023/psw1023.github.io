<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.10.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-04-11T20:54:20+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Sunwoo’s Blog</title><subtitle>Sunwoo&apos;s Dev Blog.</subtitle><author><name>Sunwoo Park</name><email>psw1023@unist.ac.kr</email></author><entry><title type="html">[cs231n] 1.Image Classfication</title><link href="http://localhost:4000/categories/theory/cs231n-1/" rel="alternate" type="text/html" title="[cs231n] 1.Image Classfication" /><published>2025-04-11T00:00:00+09:00</published><updated>2025-04-11T00:00:00+09:00</updated><id>http://localhost:4000/categories/theory/cs231n-1</id><content type="html" xml:base="http://localhost:4000/categories/theory/cs231n-1/"><![CDATA[<blockquote>
  <ul>
    <li>본 글은 Stanford University에서 2017년에 진행했던 cs231n 강의를 듣고 내용을 정리한 것입니다.<br /></li>
    <li>이번 글에서는 <a href="https://youtu.be/vT1JzLTH4G4?si=QEGiAOCUhSCkH3qx" title="Youtube: cs231n-1"><strong><code class="language-plaintext highlighter-rouge">1강</code></strong></a>과 <a href="https://youtu.be/OoUX-nOEjG0?si=jtKw1M-jjkaYBX3l" title="Youtube: cs231n-2"><strong><code class="language-plaintext highlighter-rouge">2강</code></strong></a>의 내용을 요약 및 정리하였습니다.<br />
<span style="font-size: 12px; color:rgb(56, 56, 56)">
  * <strong><code class="language-plaintext highlighter-rouge">block</code></strong> 처리된 문구를 클릭하면 해당 회차의 유튜브 영상으로 바로 갑니다.</span><br /></li>
    <li>강의가 2017년도 기준으로 제작되어 가끔씩 요즘 CV분야의 유행과는 괴리감드는 내용이 있을 수 있으나, 수강 목적이 글쓴이가 기초를 다지기 위함이라 그 점 고려해주시면 감사하겠습니다.<br /></li>
    <li>틀린 내용이 있다면 댓글을 통해 지적해주시면 감사하겠습니다.<br /></li>
  </ul>
</blockquote>

<hr />

<h1 id="ilsvrc-image-classfication-challenge">ILSVRC: Image Classfication Challenge</h1>

<p>사람들은 보다 공식적으로 Image Classification 알고리즘들의 성능을 확인 및 비교하기 위해 하나의 아주 큰 이미지 데이터셋을 만들기로 결심했습니다. 그렇게 탄생한 데이터셋이 ImageNet으로, 22K 종류의 category와 14M 개의 image로 구성되어 있습니다. 그리고 이 중 1,000개의 object class와 약 140만 개의 image를 사용하여 서로의 알고리즘을 경쟁하는 Challenge를 열기로 했고, 그것이 바로 ILSVRC 입니다.<br /></p>

<p><img src="https://i.imgur.com/OWDgYs9.png" alt="cs231n-1-fig" /></p>
<figcaption align="center">Figure 1</figcaption>

<p>대회의 방식은 아래의 다음과 같습니다. 사람들은 input image에 대해 5개의 class를 predict 합니다. 그리고 GT class가 포함되어 있다면 해당 case에 대해 통과한 것 입니다. Fig1 에서는 Steel drum에 대한 image가 주어지고, 만약 예측한 classes에 Steel drum이 포함되어 있다면 통과한 것 입니다.<br /></p>

<p><img src="https://i.imgur.com/SCdJsbF.png" alt="cs231n-1-fig" /></p>
<figcaption align="center">Figure 2</figcaption>

<p>그리고 Fig2 의 그래프를 참고하면, 2011년도와 2012년도 사이에 약 10% 가량의 오차율을 감소시킨 것을 알 수 있습니다. (x축은 수상한 알고리즘, y축은 해당 알고리즘의 오차율 입니다.) 이때 등장한 알고리즘이 바로 CNN(Convolutional Neural Network) 입니다. 본 강의에서는 앞으로 CNN에 대해 알아가는 것을 목표로 한다고 합니다.</p>

<h1 id="image-classification">Image Classification</h1>
<h2 id="overview">Overview</h2>

<p><img src="https://i.imgur.com/DppRKfd.png" alt="cs231n-1-fig" /></p>
<figcaption align="center">Figure 3</figcaption>

<p>Image Classification 은 주어진 category 내에서 input이 어떤 category에 속하는지 예측하는 문제입니다. Fig3 에서처럼 input으로 고양이 이미지가 주어지면 일련의 과정을 거쳐 output으로 cat 이라는 문자가 나와야 합니다. 하지만 사람과 달리 컴퓨터는 이미지를 일련의 숫자 모음으로 밖에 인식하지 못합니다. 즉, 우리는 이러한 일련의 숫자 모음, 벡터 값만을 가지고 classification 할 수 있는 알고리즘을 만들어야 합니다.<br /></p>

<p><img src="https://i.imgur.com/cQDwvbF.png" alt="cs231n-1-fig" /></p>
<figcaption align="center">Figure 4</figcaption>

<p>이때 명심해야할 사실 중 하나는 우리가 개발할 알고리즘은 input에 대해 강인해야만 합니다. input으로 여러 고양이가 주어진다고 했을 때, 각 고양이들은 어떠한 변화요소(viewpoint variation, illumination, occlusion, background clutter, etc) 때문에 모두 다른 형태를 띌 것입니다. 그러니까, 강인하다는 것은 이러한 변화들에도 불구하고 모두 같은 output을 내야한다는 것입니다.</p>

<h2 id="initial-approach">Initial Approach</h2>

<p>그래서 사람들이 classification 알고리즘을 개발하려하면서 처음 떠올린 방식은 모든 category들에 대해 일련의 rule을 만들자는 것이었습니다. 고양이로 예를 들면, 우선 input rgb image를 edge의 형태로 나타내고, 고양이의 귀, 입 등 특징적인 부분에 대한 변하지 않는 rule을 정해서 그러한 rule에 대해 모두 알고리즘화 시키는 것입니다. ‘귀는 edge 두 개가 만나서 하나의 corner를 이룬다’와 같은 rule 말입니다. 하지만 이러한 방식은 사실상 불가능합니다. 모든 category에 대해 이러한 rule을 일일이 만든다는 것은 불가능에 가깝죠. 심지어 만든다고 치더라도 rule이 항상 맞는다는 보장도 하기 어려울 것입니다.</p>

<h2 id="data-driven-approach">Data-driven Approach</h2>

<p>이러한 문제를 깨닫고, Data-driven적인 접근을 하게 됩니다. 방식은 다음과 같습니다.<br /></p>

<ul>
  <li>image와 label에 대한 데이터를 대량으로 모은다.</li>
  <li>Machine learning을 이용해서 classifier를 train 한다.</li>
  <li>새로운 input에 대해 classifier를 evaluate 한다.</li>
</ul>

<p>이제 계획을 위와 같이 세웠다면, classifier 의 방법론에 대해 생각해야 합니다.</p>

<h2 id="nearest-neighbor">Nearest Neighbor</h2>

<p>Nearest Neighbor 의 작동방식은 아래와 같습니다.<br /></p>

<ul>
  <li>train 단계에서는, 모든 수집한 image와 label 을 기억한다.</li>
  <li>predict 단계에서는, 기억한 데이터에서 가장 similar한 것을 찾아 label을 예측한다.</li>
</ul>

<p>그럼 한 가지 의문이 들 수 있습니다. 무엇으로 가장 similar한 것이라고 예측을 하는가 입니다. 이때 사용하는 것이 Distance Metric 입니다. 해당 강의에서는 L1 Distance와 L2 Distance에 대해 간략히 소개하는데, 이에 대해서는 아래에서 추가로 알아보도록 하고, 우선 classifier에 대해 계속해서 소개하겠습니다. (일단 예측을 할 때에는 Distance metric을 사용한다는 정도만 알아두면 되겠습니다.)<br /></p>

<p>이러한 Nearest Neighbor 방식에는 치명적인 문제점이 있습니다.<br /></p>

<p><img src="https://i.imgur.com/mtXaqay.png" alt="cs231n-1-fig" /></p>
<figcaption align="center">Figure 5</figcaption>

<p>Fig5 는 Nearest Neighbor 를 구현한 코드입니다. 코드를 살펴보면, train 파트는 단순히 data를 기억하는 단계이므로 상수 시간이 걸릴 것입니다. predict 파트는 하나하나 비교를 하면서 가장 similar한 pair를 찾는 과정으로 O(N)의 시간복잡도를 가질 것입니다.<br /></p>

<p>여기서 아주 큰 문제점이 보입니다. 우리가 추구하는 방향은 train 시간은 오래걸리더라도 test 시간은 빠를수록 좋고, 빨라야 한다는 것입니다. 하지만 NN 방식의 경우에는 정반대이므로 이에 대한 개선책이 필요할 것입니다.<br />
밑에 서술할 parametric model 중 가장 simple한 종류인 Linear classifier가 이러한 문제를 해결하기 위한 시도의 첫걸음인데, 일단 이에 관해 알아보기 전에 여전히 해당 문제점은 가지고 있지만 Nearest Neighbor의 성능을 더 향상시키기 위해 등장한 다른 classifier에 대해서도 하나 더 알아봅시다.</p>

<h2 id="k-nearest-neighbor">K-Nearest Neighbor</h2>

<p>위의 NN 방식에서는 가장 similar한 이미지만을 찾았다면, K-Nearest Neighbor 방식에서는 k 를 지정하고, k 개의 similar한 이미지를 찾은 뒤, 더 많이 해당되는 category에 본인도 포함되는 것입니다.</p>

<p><img src="https://i.imgur.com/dzNyVde.png" alt="cs231n-1-fig" /></p>
<figcaption align="center">Figure 6</figcaption>

<p>Fig6 에서 초록색 영역의 중앙에 끼여있는 노란색 점에 대해 해석한 결과는 아래와 같습니다.</p>

<ul>
  <li>K=1(NN의 case) 일 때, 만약 초록색 category에 해당하는 input이 초록색 영역에 끼여있는 노란색 영역에 위치한다면 초록색 category임에도 불구하고 노란색 category로 predict 될 것임.</li>
  <li>K=3,5 일 때, K=1 일 때 기준으로 해당 노란 영역에 포함되더라도, 중앙의 노란점 하나와의 거리만으로 판단하는 것이 아닌, 주위의 초록색 점도 각각 2개, 4개를 추가로 인식하여 vote한 뒤, predict 하므로, 초록색 category로 올바르게 predict 될 것임.</li>
</ul>

<p>이러한 예시와 같이, K-Nearest Neighbor는 K 값과 Distance metric을 사용하여 최종적으로 category를 예측할 것이고 K=1의 경우보다 성능이 좋을 것임을 예상할 수 있습니다.</p>

<h2 id="distance-metric">Distance Metric</h2>

<p>Parametric model 방식을 알아보기 전에, 앞서 언급했던 distance metric에 대해 알아봅시다. Distance metric 은 한글로 생각하면 거리 측정 인데, 말 그대로 픽셀간의 거리를 측정한다고 생각할 수 있습니다.</p>

<p><img src="https://i.imgur.com/ekVFc4V.png" alt="cs231n-1-fig" /></p>
<figcaption align="center">Figure 7</figcaption>

<p>Fig7 은 대표적인 distance metric 중 하나인 L1 Distance(= Manhattan Distance) 를 사용해서 4x4 size의 train image와 test image 사이의 거리를 측정한 예시입니다. 그림에서 보이는 그대로 각 pixel 값에 대응하는 수를 서로 빼주고 절댓값을 씌워준 뒤 나온 값들을 모두 더해주면 그 값이 L1 Distance에 해당하는 거리값이 됩니다.<br /></p>

<p>본 강의에서는 L1 Distance와 L2 Distance에 대해 간단히 설명합니다.</p>

<p><img src="https://i.imgur.com/JBDyLuo.png" alt="cs231n-1-fig" /></p>
<figcaption align="center">Figure 8</figcaption>

<p>Fig8 의 수식을 보면 두 distance에 대한 차이가 확실히 보일 것입니다. 그 아래의 그래프는 중심으로부터 각각의 distance metric으로 거리를 측정했을 때, 거리가 같은 점들의 집합을 나타낸 것입니다. L1 dist. 의 경우에는 마름모꼴로, L2 dist. 의 경우에는 원의 형태로 나타나는 것을 알 수 있습니다.</p>

<p>L1 distance와 L2 distance 중 어떤 metric을 고를 지는 매우 problem-dependent하지만, 강의에서는 최소한의 가이드라인으로서 데이터셋이 좌표계에 의존적이라면 주로 L1, 보다 일반적이라면 주로 L2를 우선적으로 사용해보라고 답변해줍니다. 좌표계의 의존적이라는 것의 의미는 데이터가 특정 정보 요소들에 영향을 많이 받는, 즉 그러한 요소들이 중요한 경우라고 저는 이해했습니다.</p>

<h2 id="parametric-approach">Parametric Approach</h2>

<p>앞서 우리는 Data-driven Approach에 해당하는 방식들(e.g. NN, kNN ..)이 train 시간은 짧지만 test 시간이 길어진다는 문제점이 있다고 했습니다. 이를 해결하기 위한 접근이자 현재도 사용하는 방식이 바로 Parametric Approach 입니다. 이번 강의에서는 가장 간단한 형태인 Linear classifier에 대해 알아봅니다. <br /></p>

<p><img src="https://i.imgur.com/QoFwRds.png" alt="cs231n-1-fig" /></p>
<figcaption align="center">Figure 9</figcaption>

<p><img src="https://i.imgur.com/HDPr3r1.png" alt="cs231n-1-fig" /></p>
<figcaption align="center">Figure 10</figcaption>

<p>Linear classifier는 Fig9 와 같이, function f 를 정의해서 input이 각 category와 similar한 정도를 score화 시켜 classification 문제를 해결합니다. 이때, f는 f(x, W)의 형태를 띄는데, x는 input을, W는 weight matrix를 나타냅니다. 즉, Parametric approach는 train 단계에서 모든 데이터를 기억하여 이후 test하는 방식 대신, train 단계에서 parameter를 따로 정의해서 train dataset들로 해당 parameter를 학습하는 방식을 사용합니다. 결과적으로 predict 단계에서는 이미 학습된 parameter만으로 output을 예측하므로 이전의 방식에 비해 훨씬 빠른 속도로 predict 합니다.</p>

<p>Fig10 에서는 b로 표현된 bias 항이 추가된 것을 볼 수 있는데, 보통 bias 항은 train dataset이 불균형할 때 가중치를 주는 역할을 하기도 합니다. 예를 들어, 고양이와 강아지를 분류하는 Linear classifier를 구현하려는데, train dataset에는 고양이의 사진의 비율이 다소 높을 때, bias 항을 도입하여 W 를 학습할 때 참고하라고 알려주는 것입니다.</p>

<p><img src="https://i.imgur.com/RMeZypp.png" alt="cs231n-1-fig" /></p>
<figcaption align="center">Figure 11</figcaption>

<p>Fig10 의 수식을 시각화한 것이 Fig11 입니다. 해당 사진을 보시면 더욱 이해가 잘 될 것입니다.</p>

<p><img src="https://i.imgur.com/9UwGDfC.png" alt="cs231n-1-fig" /></p>
<figcaption align="center">Figure 12</figcaption>

<p><img src="https://i.imgur.com/feT1nh4.png" alt="cs231n-1-fig" /></p>
<figcaption align="center">Figure 13</figcaption>

<p>하지만, Linear classifier에도 한계가 있습니다. Fig12 에서 보이듯이 Linear classifier는 하나의 linear한 선으로 data들을 classify 합니다. 따라서, 하나의 선으로 분류하기 힘든 데이터들의 경우에는 당연히 어려움을 겪을 것입니다. 대표적으로 Fig13 의 경우들이 그러할 것입니다.</p>]]></content><author><name>Sunwoo Park</name><email>psw1023@unist.ac.kr</email></author><category term="Theory" /><summary type="html"><![CDATA[cs231n (1)]]></summary></entry></feed>